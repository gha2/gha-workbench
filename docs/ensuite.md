<table style="width: 100%"><tr>
    <td style="width: 33%; text-align: left"><a href="utilisation_spark_operator.md"><- Utilisation au travers de l'Opérateur Spark</a></td>
    <td style="width: 33%; text-align: center"><a href="../README.md">HOME</a></td>
    <td style="width: 33%; text-align: right"></td>
</tr></table>

# Ensuite....

- Déploiement AWS (S3 de référence)
- Benchmark (TPC-DS, ....)
- Monitoring
- Etude de l'utilisation du stockage (Shuffle/Spilling)
- Node affinity
- Gestion des droits S3 (Onpremise (Vault) and AWS)
- Jupyter notebook
- [Apache Livy](https://livy.incubator.apache.org/)
- Presto  
- [Securisation](http://spark.apache.org/docs/latest/security.html).
- Test de résilience / chaos monkey
- Remplacer Spark History Server par [delight](https://github.com/datamechanics/delight)
- Tester [data mechanics platform](https://www.datamechanics.co/)
- Spark Streaming
- Etude [ALLUXIO](https://www.alluxio.io/)  
- Etude [dremio](https://www.dremio.com/) 
- Etude [DeltaLake](https://delta.io/)
- Etude [YuniKorn](http://yunikorn.apache.org/)
- Access (beeline, JDBC, spark Thrift server)
- [querybook](https://www.querybook.org/)
- [Ozone](https://ozone.apache.org/)
- Trouver un opérateur S3 pour gestion des buckets


Done (To document)

- Activer le cleaner sur spark-history-server (https://stackoverflow.com/questions/42817924/cleaning-up-spark-history-logs)

<table style="width: 100%"><tr>
    <td style="width: 33%; text-align: left"><a href="utilisation_spark_operator.md"><- Utilisation au travers de l'Opérateur Spark</a></td>
    <td style="width: 33%; text-align: center"><a href="../README.md">HOME</a></td>
    <td style="width: 33%; text-align: right"></td>
</tr></table>


