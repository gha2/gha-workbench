# Ensuite....

- Benchmark (TPC-DS, ....)
- Monitoring
- Etude de l'utilisation du stockage (Shuffle/Spilling)
- Node affinity
- Activer le cleaner sur spark-history-server (https://stackoverflow.com/questions/42817924/cleaning-up-spark-history-logs)
- Gestion des droits S3
- Jupyter notebook
- [Apache Livy](https://livy.incubator.apache.org/)
- [Securisation](http://spark.apache.org/docs/latest/security.html).
- Test de résilience / chaos monkey
- Spark Streaming
- Déploiement AWS (S3 de référence)
- Etude [DeltaLake](https://delta.io/)
- Etude [YuniKorn](http://yunikorn.apache.org/)
- Access (beeline, JDBC, spark Thrift server)
- [querybook](https://www.querybook.org/)
- HDFS on kubernetes ?
- [Ozone](https://ozone.apache.org/)
- Trouver un opérateur S3 pour gestion des buckets

Done (To document)

- [spark operator](https://github.com/GoogleCloudPlatform/spark-on-k8s-operator)



